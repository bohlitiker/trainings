{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV\n",
    "`openCV` is probably the most widely used open-source image library used in C++ and Python. It provides a lot of functionalities to manipulate images. Some of which will be discussed in this notebook.\n",
    "\n",
    "Its basic functionalities contain\n",
    "- importing images\n",
    "- changing colourspaces (RGB, BGR, HSV, Grayscale etc.)\n",
    "- edge detection\n",
    "- finding contours in images\n",
    "- rotating images\n",
    "\n",
    "and many more. An extensive documentation including examples can be found [[here]](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html).\n",
    "\n",
    "More complex functionalities are for example gesture recognition and face detection which are provided by openCV for free and can be encorporated into software if required.\n",
    "\n",
    "The first step here is downloading the library, since it is not part of Python's default libraries. There are two different libraries of `openCV` available for download. The \"normal\" and the \"contribution\" version. The \"contribution\" version contains a lot more functions that do not 100% work with all operating systems. The functions we will be using here are all part of the \"normal\" distribution. So it is your own choice which to install. Both versions below.\n",
    "\n",
    "`pip install opencv-python`\n",
    "\n",
    "`pip install opencv-contrib-python`\n",
    "\n",
    "After doing this, we first import the library and then create a variable for an image and plot it using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#loading an image to a variable\n",
    "img = cv2.imread('mark_0.jpg')\n",
    "#plotting image\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the imqge is plotted just like the numpy arrays in the previous course. `OpenCV` has its own function for plotting. The reason `matplotlib` is used here is for its additional functionalities besides displaying images such as zooming, being able to access pixel information and automatically scaling the image to the window.\n",
    "\n",
    "An example for `openCV's` plotting function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting image. Title is necessary\n",
    "cv2.imshow('image title',img)\n",
    "#this function loops, and the waitkey tells how long to wait during each loop.\n",
    "#software freezes/crashes if forgotten\n",
    "cv2.waitKey(0)\n",
    "#all windows destroyed when closed. Otherwise new window would be opened \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "\n",
    "The images from the `matplotlib` and `openCV` `imshow()` functions are different. Can you guess what happened?\n",
    "\n",
    "**Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Images\n",
    "The ability to save images is instrumental when working on them. `openCV` provides the `imwrite()` function for this. It requires a name and an image. It automatically overwrites images of the same name, so be careful when naming images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving image to directory\n",
    "cv2.imwrite('myImage_INTP.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Colorspaces\n",
    "The RGB Colourscheme is something everyone should be familiar with. It contains all the displayable colours of an image in three channels with a minimum value of 0 and a maximum value of 255 for each channel. These channels are R --> RED, G --> Green, B --> Blue.\n",
    "\n",
    "Images in `openCV` are `numpy` arrays of shape (n Rows, m Columns, 3) with the third dimension being the colour channels. Sometimes there is a fourth `alpha` channel used for transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different colourspaces available in `openCV` the four most commonly used ones were already mentioned. RGB, BGR, HSV and Grayscale.\n",
    "- RGB( 3 channels) --> Red, Green, Blue\n",
    "- BGR( 3 channels) --> Blue, Green, Red\n",
    "- HSV( 3 channels) --> Hue (colour tone/tint), saturation, value (lightness)\n",
    "- Gray( 1 channel) --> Gray\n",
    "\n",
    "They each have different advantages when working with images, some of which will be explained at a later point. `openCV` provides a function to convert these colourspaces called `cvtColor()`.\n",
    "\n",
    "It requires the image and the two colourspaces between which to convert as an input. Some examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bgr to grayscale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(131),plt.title('Grayscale'), plt.imshow(img_gray, cmap = 'gray')\n",
    "plt.subplot(132),plt.title('RGB'), plt.imshow(img_rgb)\n",
    "plt.subplot(133),plt.title('BGR'), plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Selecting image cut-outs\n",
    "Since images are `numpy` arrays, `slicing` and any other `numpy` operations are possible on them. `openCV` provides some of these functions itself as well. Slicing is done exactly the same way as before. This image slice can also be saved as an independent image file if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_part = img_rgb[10:100,10:100,:]\n",
    "plt.imshow(img_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Resizing image\n",
    "Resizing images is an important step for data pre-processing in the field of deep-learning. As networks are trained on a certain image shape, it is necessary to bring images into the required shape. `openCV` provides the aptly named `resize()` function for this. Its arguments are as follows:\n",
    "- image to resize\n",
    "- new size as a tuple (height, width)\n",
    "- interpolation method\n",
    "\n",
    "Resizing images results in a new resolution of the image. This also means that the pixels' values are changed. How they are adapted is decided by the interpolation method. A short description on this can be found [here](https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/).\n",
    "\n",
    "In the following example we are going to downsample the `img` we previously used to 80% of its original size. We will output the shape of both the original and the resized image.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Why is the command `int()` used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting shape\n",
    "original_shape = img.shape\n",
    "print('Original Shape:',original_shape)\n",
    "\n",
    "#setting new shape to 80% of original\n",
    "new_width = int(original_shape[0]*5)\n",
    "new_height = int(original_shape[1]*5)\n",
    "\n",
    "#resizing image\n",
    "resized_img = cv2.resize(img, (new_height, new_width), cv2.INTER_LANCZOS4)\n",
    "print('New Shape:', resized_img.shape)\n",
    "\n",
    "#displaying image\n",
    "cv2.imshow('New Image',resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Image Thresholding\n",
    "Thresholding is very similar to using masks in `numpy`. Thresholding can be done on colour images as well as graysscale images, in this example we will use a colour image. Using a colour image, a threshold for the pixelvalue is set. Any pixel above or below this value ( depending on the algorithm)  will be set to the maximum value set as the third argument in function. Please keep consolodating the [official documentation](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html) for extensive information, as this is more of a general overview.\n",
    "\n",
    "The `cv2.threshold()` function arguments are:\n",
    "- the image to do thresholding on\n",
    "- the threshold lower bound\n",
    "- maximum value\n",
    "- the operations on the values inside and outside the boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retVal,thresholding_img = cv2.threshold(img,30,255,cv2.THRESH_BINARY)\n",
    "plt.imshow(thresholding_img, cmap = 'gray')\n",
    "print('Max value:', np.max(thresholding_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "\n",
    "Now use this `thresholding_img` to create a mask and change every pixel of the `img` variable that overlaps with the mask's *black* pixels into a white pixel.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check, if the image still has three colour channels. If yes, change it to grayscale\n",
    "if len(thresholding_img.shape) > 2:\n",
    "    thresholding_img = cv2.cvtColor(thresholding_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#create mask    \n",
    "mask_task1 = thresholding_img == 0\n",
    "\n",
    "#create copy of original image, so the original is not changed\n",
    "img_task1 = np.copy(img)\n",
    "# use mask\n",
    "img_task1[mask_task1] = [255,255,255]\n",
    "\n",
    "#display image\n",
    "cv2.imshow('My Image',img_task1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {
    "grafik.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Edge Detection\n",
    "Edge detection makes it possible to find outlines of objects in images. This is done by iterating over an image using a `kernel`. That highlights drastic colour changes in images and thereby decides where the outlines of objects are.\n",
    "\n",
    "Two of such kernels are shown below. The **x-Direction** kernel finds vertical lines and the **y-Direction** kernel finds horizontal lines.\n",
    "![grafik.png](attachment:grafik.png)\n",
    "\n",
    "These kernels are not only used for edge detection but are the basis on which spatial dependencies in image recognition and classificaiton software work. Namely the Deep Learning method *Convolutional Neural Networks*.\n",
    "\n",
    "The `Canny()` class of the `openCV` library implements this automatically. The required arguements are:\n",
    "- input image --> MUST be grayscale\n",
    "- minimum value for edge detection\n",
    "- maximum value for edge detection\n",
    "- optionally the kernelsize can be changed. By default it is a 3x3 kernel.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "What difference can be seen between the two outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge1 = cv2.Canny(img_gray, 0, 255)\n",
    "#different bounds\n",
    "edge2 = cv2.Canny(img_gray, 60, 255)\n",
    "plt.subplot(121),plt.title('First'), plt.imshow(edge1, cmap = 'gray')\n",
    "plt.subplot(122),plt.title('Second'), plt.imshow(edge2, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Webcam to stream video\n",
    "Using images from the computer is all nice and good, but we also want to use the images taken from our own devices or even use a livestream or provided video.\n",
    "\n",
    "To access your computer's camera and output the images it takes openCV provides the `VideoCapture()` class. It takes one argument which can be either a `string` pointing to a file or an integer. The integer is pointing at the camera with `0` being the default device of your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the outputof the camera, use the following `read()` function which return a boolean and the image. The boolean states, whether or not an image was returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,frame = cap.read()\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can get an image and plot it, we want a livestream as well. By using an endless `while` loop it is possible to stream the video from the camera. By default the FPS (Frames per second) is 30. This is plenty for normal tasks.\n",
    "\n",
    "Now we only need to output the image not using `matplotlib` but `openCV's` own function for image output, which we have already used before.\n",
    "\n",
    "Since it will be necessary to exit the while loop at some point, we also create a condition for it. In this example the while loop will be exited once the **q** button on the keyboard is used.\n",
    "\n",
    "You could also save the current image when **q** is pressed.\n",
    "\n",
    "In the end all windows created by this while loop are destroyed and the camera is released, meaning it is no longer blocked for other software by this program.\n",
    "\n",
    "Since you may want to use this loop multiple times, the `cap.release()` function is disabled by default. You are free to enable it, but then remember to call the `VideoCapture()` class again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #getting images from camera\n",
    "    ret ,frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        #show image in window\n",
    "        cv2.imshow('Livestream',frame)\n",
    "\n",
    "        #specify what should happen if certain keys are pressed.\n",
    "        #Add more keys for more functions or multiple functions for one button\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            cv2.imwrite('video_test.jpg', frame)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "#destroy all windows, otherwise the frame would keep popping up\n",
    "cv2.destroyAllWindows()\n",
    "# release camera\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an explanation why `& 0xFF` is used together with the `cv2.waitKey()` command, take a look at this [stackOverflow Thread](https://stackoverflow.com/questions/14713102/what-does-and-0xff-do)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Thresholding to a livestream video\n",
    "The operations done on single images can also be applied to a livestream. And as long as the images are not too large and the computer is fast enough, it will work without a delay.\n",
    "\n",
    "In the following example thresholding is applied to the livestream. This time `thresholding` will be applied to a grayscaled image.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #getting images from camera\n",
    "    ret ,frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        retVal,thresholding_img = cv2.threshold(gray,80,255,cv2.THRESH_BINARY)\n",
    "        #show image in window\n",
    "        cv2.imshow('Livestream',thresholding_img)\n",
    "\n",
    "        #specify what should happen if certain keys are pressed.\n",
    "        #Add more keys for more functions or multiple functions for one button\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "#destroy all windows, otherwise the frame would keep popping up\n",
    "cv2.destroyAllWindows()\n",
    "# release camera\n",
    "#cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a mask for the original image\n",
    "The argument `cv2.THRESH_BINARY` states that the returned image should only be of two values. Which is 0 for all pixels below the threshold and 255 for all pixels above it.\n",
    "\n",
    "This makes it easy to create a mask and use slicing on the original image to return only those pixels above that were above the threshold but in the colored image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #getting images from camera\n",
    "    ret ,frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        retVal,thresholding_img = cv2.threshold(gray,80,255,cv2.THRESH_BINARY)\n",
    "        \n",
    "        #creating mask that is true where img below threshold\n",
    "        mask = thresholding_img == 0\n",
    "        \n",
    "        #creating a copy of the original image\n",
    "        filtered = np.copy(frame)\n",
    "        #applying mask to original image and change pixels to black\n",
    "        filtered[mask] = [0,0,0]\n",
    "        #putting images next to each other \n",
    "        complete_img = np.hstack((frame, filtered))\n",
    "        #show image in window\n",
    "        cv2.imshow('Livestream',complete_img)\n",
    "\n",
    "        #specify what should happen if certain keys are pressed.\n",
    "        #Add more keys for more functions or multiple functions for one button\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "#destroy all windows, otherwise the frame would keep popping up\n",
    "cv2.destroyAllWindows()\n",
    "# release camera\n",
    "#cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Now, do the thing for the edge detection. Only the result should be, that the detected edges should be visible in the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #getting images from camera\n",
    "    ret ,frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #using edge detection\n",
    "        edges = cv2.Canny(gray, 60, 255)\n",
    "        \n",
    "        #creating mask that is true where there are edges detected\n",
    "        mask = edges != 0\n",
    "        \n",
    "        #creating a copy of the original image\n",
    "        original_edges = np.copy(frame)\n",
    "        #applying mask to original image and change pixels to black\n",
    "        original_edges[mask] = [0,0,0]\n",
    "        #putting images next to each other \n",
    "        complete_img = np.hstack((frame, original_edges))\n",
    "        #show image in window\n",
    "        cv2.imshow('Livestream',complete_img)\n",
    "\n",
    "        #specify what should happen if certain keys are pressed.\n",
    "        #Add more keys for more functions or multiple functions for one button\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "#destroy all windows, otherwise the frame would keep popping up\n",
    "cv2.destroyAllWindows()\n",
    "# release camera\n",
    "#cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Contours in images\n",
    "Contours are similar to edges. The difference is, that contours are not returned as an array of the same dimensions as the input image, but as a list of numpy arrays. This list contains all the different contours found in an image. Each item in the list is a different contour, which can be used for various tasks such as\n",
    "- tracking of objects\n",
    "- estimating size and shape\n",
    "finding the center of an object\n",
    "\n",
    "The openCV function `findContours()` enables looking for contours in a grayscale image. It takes three input agruments:\n",
    "- input image\n",
    "- which contour layers to look for\n",
    "- approximation type for contours\n",
    "\n",
    "Of these, the second argument is important because it lets the user choose whether to only take the outer contour or a hierarchy of contours. For more detailed information on the **Hierarchy** go to the official [documentation](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contours_hierarchy/py_contours_hierarchy.html#contours-hierarchy)\n",
    "\n",
    "The following example will return both, only the outside and the hierarchical contours in two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_image = cv2.imread('mark_2.jpg')\n",
    "#changign colourspace for plotting\n",
    "contour_image = cv2.cvtColor(contour_image, cv2.COLOR_BGR2RGB)\n",
    "#changing image to grayscale\n",
    "img_grayscale = cv2.cvtColor(contour_image, cv2.COLOR_RGB2GRAY)\n",
    "#Thresholding image\n",
    "ret,thresh = cv2.threshold(img_grayscale,80,255,cv2.THRESH_BINARY)\n",
    "#plotting images\n",
    "plt.subplot(121), plt.title('original'),plt.imshow(contour_image, cmap = 'gray')\n",
    "plt.subplot(122), plt.title('threshold'),plt.imshow(thresh, cmap = 'gray')\n",
    "\n",
    "#getting contours of outer layer\n",
    "outer_contour, outer_hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "#Getting contours of multiple layers\n",
    "contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "print('\\nOuter Contour:\\n',len(outer_contour))\n",
    "print('Number of Contours:\\n',len(contours))\n",
    "for idx,contour in enumerate(contours):\n",
    "    print('Points in contour', idx, ':',len(contour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen, that many of the contours only have very few points. These are small areas that were mistakenly included in the contours. We will ignore them in the later detection.\n",
    "\n",
    "If you only draw the points of the contours, you will get something like a scatter plot, since a new point is only set if the next pixel of the contour is not in a straight line with the past to pixels. So it is something like a **connect the dots** image.\n",
    "\n",
    "The next task is to draw all the contours in our image. For this we will create a copy of the original image and so we do not have to reload it, since the markings will be permanent for the image.\n",
    "\n",
    "OpenCV's `drawContours()` function will draw the contours for us. We can either draw all contours or draw them one at a time and leave out all contours with few points.\n",
    "\n",
    "The `drawContours()` function takes five arguments:\n",
    "- the image to draw on\n",
    "- the contour or list of contours to draw\n",
    "- index of contours --> -1 to draw all contours\n",
    "- colour of contour\n",
    "- thickness of contour --> -1 will fill the contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating copy\n",
    "overlay = np.copy(contour_image)\n",
    "\n",
    "#iterating over contours\n",
    "list_of_contours_to_plot = []\n",
    "#filling list of contours\n",
    "for contour in contours:\n",
    "    if len(contour) > 10: list_of_contours_to_plot.append(contour)\n",
    "        \n",
    "overlay = cv2.drawContours(overlay, list_of_contours_to_plot, 6, (0,255,0), -1)\n",
    "    \n",
    "plt.imshow(overlay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example will only take one contour and fill it in completely with colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating copy\n",
    "overlay = np.copy(contour_image)\n",
    "\n",
    "#iterating over contours\n",
    "list_of_contours_to_plot = []\n",
    "#filling list of contours\n",
    "for contour in contours:\n",
    "    if len(contour) > 10: list_of_contours_to_plot.append(contour)\n",
    "        \n",
    "overlay = cv2.drawContours(overlay, list_of_contours_to_plot, 4, (0,255,0), -1)\n",
    "    \n",
    "plt.imshow(overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of different operations can be done on contours at this point such as finding its center or its most northern, eastern, southern or western point. Check the [documentation](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.html) for more detailed information.\n",
    "\n",
    "We will do some slicing again.\n",
    "\n",
    "The first step is to create a mask. We will use our overlay image for this. We gave all the pixels the colour green (0,255,0) it is very unlikely that any real object has exactly this colour, to we will only extract these points from the image to create a mask and return that area from the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating mask\n",
    "#mask has to be two dimensional, so we only take second layer\n",
    "mask_contours = overlay[:,:,1] != 255\n",
    "\n",
    "#using mask on original image\n",
    "cut_out = np.copy(contour_image)\n",
    "cut_out[mask_contours] = [0,0,0]\n",
    "\n",
    "#plotting \n",
    "plt.subplot(121), plt.title('mask'),plt.imshow(mask_contours, cmap = 'gray')\n",
    "plt.subplot(122), plt.title('cut_out'),plt.imshow(cut_out, cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Try using contour detection on a live videostream. What are the results? Does it work well? Could it be used to track objects? How can you improve the recognition? Did you find any other openCV functions that could be used to track objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #getting images from camera\n",
    "    ret ,frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #using edge detection\n",
    "        thres_return,thresh = cv2.threshold(gray,150,200,cv2.THRESH_BINARY)\n",
    "        #Getting contours of multiple layers\n",
    "        contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "        list_of_contours_to_plot = []\n",
    "        for contour in contours:\n",
    "            if len(contour) > 10: list_of_contours_to_plot.append(contour)\n",
    "        \n",
    "        #creating a copy of the original image\n",
    "        overlay = np.copy(frame)\n",
    "        overlay = cv2.drawContours(overlay, list_of_contours_to_plot, -1, (0,255,0), 1)\n",
    "        #applying mask to original image and change pixels to black\n",
    "        #putting images next to each other \n",
    "        complete_img = np.hstack((frame, overlay))\n",
    "        #show image in window\n",
    "        cv2.imshow('Livestream',complete_img)\n",
    "\n",
    "        #specify what should happen if certain keys are pressed.\n",
    "        #Add more keys for more functions or multiple functions for one button\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "#destroy all windows, otherwise the frame would keep popping up\n",
    "cv2.destroyAllWindows()\n",
    "# release camera\n",
    "#cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The HSV Colourspace\n",
    "\n",
    "The HSV and RGB/BGR colourspaces differ greatly in their set-up and their applications. One of them is colourtracking. \n",
    "The RGB/BGR colourspace should be familiar to most.\n",
    "\n",
    "![title](rgb.png)\n",
    "\n",
    "The problem when tracking clours in the RGB clourspace come when you want to track a range of colours. If only a certain RGB should be tracked, this is no problem, but if the colour **Blue** should be tracked, it means every RGB value in a certain range. Which could be from light blue (RGB = \\[63,242,252\\]) to dark blue (RGB = \\[35,40,245\\]. The problem arises when iterating over the interval. What are the minimum and maximum values for each colour channel and what about the gray values? This is a major problem, since they must be ommitted in a very complicated way.\n",
    "\n",
    "This is where the HSV colourscale shows its uses. The difference is in its three values. That, as explained before, are Hue (colour tone), Saturation, Value (lightness). A good representation of the colourspace is a cone.\n",
    "\n",
    "![title](hsv.jpg)\n",
    "\n",
    "By using the HSV colourspace and setting the **S**aturation and **V**alue to a reasonable minimum it is easy to select variety of similar colours in an iterval.\n",
    "\n",
    "A good explanation on this and an interface to check colours can be found [here](http://colorizer.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Now this next task is a bit more complex and contains multiple steps. What you have to do is creating an algorithms to display only certain fields of the following rubik's cube image.\n",
    "\n",
    "![title](rubiks_cube.jpg)\n",
    "\n",
    "1. Create a program that finds all green, red and blue fields in an image **separately** and plot these images next to each other in a single `openCV` window using `cv2.imshow()`.\n",
    "2. Now take one of these, let's call them **Colourtrackers** , and use them on a livestream video from your camera and try to display only coloured objects.\n",
    "\n",
    "Additional Task:\n",
    "\n",
    "Try tracking the center of this object and display it in the original image. Here are some hints:\n",
    "- make all highlighted colours the same value\n",
    "- draw a shape on your original image based on this center using the `cv2.rectangle()` or `cv2.circle()` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution\n",
    "\n",
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubik_img = cv2.imread('rubiks_cube.jpg')\n",
    "#change colourspace to hsv\n",
    "rubik_img_hsv = cv2.cvtColor(rubik_img, cv2.COLOR_BGR2HSV)\n",
    "red, green, blue = np.copy(rubik_img),np.copy(rubik_img),np.copy(rubik_img)\n",
    "red_bounds = np.array([[0,50,50],[20,255,255]])\n",
    "green_bounds = np.array([[50,50,50],[70,255,255]])\n",
    "blue_bounds = np.array([[110,50,50],[130,255,255]])\n",
    "\n",
    "red_mask = cv2.inRange(rubik_img_hsv, red_bounds[0], red_bounds[1])\n",
    "red = cv2.bitwise_and(red, red, mask=red_mask)\n",
    "green_mask = cv2.inRange(rubik_img_hsv, green_bounds[0], green_bounds[1])\n",
    "green = cv2.bitwise_and(green, green, mask=green_mask)\n",
    "blue_mask = cv2.inRange(rubik_img_hsv, blue_bounds[0], blue_bounds[1])\n",
    "blue = cv2.bitwise_and(blue, blue, mask=blue_mask)\n",
    "\n",
    "all_images = np.hstack((rubik_img, red, green, blue))\n",
    "cv2.imshow(\"Rubik's Cube Images\",all_images)\n",
    "#this function loops, and the waitkey tells how long to wait during each loop.\n",
    "#software freezes/crashes if forgotten\n",
    "\n",
    "cv2.waitKey(0)\n",
    "#all windows destroyed when closed. Otherwise new window would be opened \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution\n",
    "\n",
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapt bounds if necessary\n",
    "red_bounds = np.array([[0,50,50],[20,255,255]])\n",
    "green_bounds = np.array([[50,50,50],[70,255,255]])\n",
    "blue_bounds = np.array([[110,50,50],[130,255,255]])\n",
    "\n",
    "while True:\n",
    "    #getting images from camera\n",
    "    ret ,frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        overlay = np.copy(frame)\n",
    "        img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        #change bounds to track or add additional bounds in another mask to track more colours\n",
    "        mask = cv2.inRange(img_hsv, blue_bounds[0], blue_bounds[1])\n",
    "        overlay = cv2.bitwise_and(overlay, overlay, mask=mask)\n",
    "        complete_img = np.hstack((frame, overlay))\n",
    "        #show image in window\n",
    "        cv2.imshow('Livestream',complete_img)\n",
    "\n",
    "        #specify what should happen if certain keys are pressed.\n",
    "        #Add more keys for more functions or multiple functions for one button\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "#destroy all windows, otherwise the frame would keep popping up\n",
    "cv2.destroyAllWindows()\n",
    "# release camera\n",
    "#cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution Additional Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_bounds = np.array([[0,50,50],[20,255,255]])\n",
    "green_bounds = np.array([[40,80,80],[90,255,255]])\n",
    "blue_bounds = np.array([[110,50,50],[130,255,255]])\n",
    "\n",
    "while True:\n",
    "    #getting images from camera\n",
    "    ret ,frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        overlay = np.copy(frame)\n",
    "        img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        #change bounds to track or add additional bounds in another mask to track more colours\n",
    "        #tracking the green colour in this solution\n",
    "        mask = cv2.inRange(img_hsv, green_bounds[0], green_bounds[1])\n",
    "        \n",
    "        #finding all pixels in the mask, that are true and \n",
    "        #taking the average of their x and y values\n",
    "        counter = 0\n",
    "        x,y = 0,0\n",
    "        for idx, pixel in np.ndenumerate(mask):\n",
    "            if pixel:\n",
    "                x += idx[1]\n",
    "                y += idx[0]\n",
    "                counter += 1\n",
    "        \n",
    "        #if there is at least one pixel of the colour\n",
    "        if counter > 0:\n",
    "            x = int(x/counter)\n",
    "            y = int(y/counter)\n",
    "            #drawing a circle around the center\n",
    "            cv2.circle(overlay, (x,y), 40, 2)\n",
    "        \n",
    "        complete_img = np.hstack((frame, overlay))\n",
    "        #show image in window\n",
    "        cv2.imshow('Livestream',complete_img)\n",
    "\n",
    "        #specify what should happen if certain keys are pressed.\n",
    "        #Add more keys for more functions or multiple functions for one button\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "#destroy all windows, otherwise the frame would keep popping up\n",
    "cv2.destroyAllWindows()\n",
    "# release camera\n",
    "#cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": "16",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
